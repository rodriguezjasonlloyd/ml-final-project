{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X1WyJhxYBwci"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field, replace, asdict\n",
    "from typing import List, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataConfig:\n",
    "    data_dir: str = \"data\"\n",
    "    img_size: int = 224\n",
    "    batch_size: int = 32\n",
    "    validation_split: float = 0.2\n",
    "    seed: int = 123\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    backbone: str = \"EfficientNetB0\"\n",
    "    pretrained: bool = True\n",
    "    unfreeze_blocks: int = 1\n",
    "    blocks_to_unfreeze: Optional[List[int]] = None\n",
    "    dropout_rate: float = 0.2\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    epochs: int = 10\n",
    "    learning_rate: float = 1e-4\n",
    "    optimizer: str = \"Adam\"\n",
    "    loss: str = \"binary_crossentropy\"\n",
    "    metrics: List[str] = field(default_factory=lambda: [\"accuracy\"])\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CallbackConfig:\n",
    "    tensorboard_logdir: str = \"logs/\"\n",
    "    checkpoint_dir: str = \"checkpoints/\"\n",
    "    model_save_dir: str = \"saved_models/\"\n",
    "    save_model: bool = False\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExperimentConfig:\n",
    "    data: DataConfig = field(default_factory=DataConfig)\n",
    "    model: ModelConfig = field(default_factory=ModelConfig)\n",
    "    training: TrainingConfig = field(default_factory=TrainingConfig)\n",
    "    callbacks: CallbackConfig = field(default_factory=CallbackConfig)\n",
    "\n",
    "\n",
    "def print_block(title: str, data: dict):\n",
    "    labels = {\n",
    "        k: (f\"{v:.2f}\" if isinstance(v, float) else str(v)) for k, v in data.items()\n",
    "    }\n",
    "    lbl_w = max(len(k) for k in labels)\n",
    "    val_w = max(len(v) for v in labels.values())\n",
    "    total_w = lbl_w + 2 + val_w + 2\n",
    "    title_str = f\" {title} \"\n",
    "    border = \"=\" * max(len(title_str), total_w)\n",
    "    print(f\"\\n{border}\")\n",
    "    print(title_str.center(len(border)))\n",
    "    print(border)\n",
    "    for k, v in labels.items():\n",
    "        print(f\"{k.ljust(lbl_w)} : {v.rjust(val_w)}\")\n",
    "    print(border + \"\\n\")\n",
    "\n",
    "\n",
    "def summarize_model(base):\n",
    "    block_layers = {}\n",
    "    block_trainable = {}\n",
    "    for layer in base.layers:\n",
    "        m = re.match(r\"^block(\\d+)[a-z]?_\", layer.name)\n",
    "        blk = int(m.group(1)) if m else 0\n",
    "        block_layers[blk] = block_layers.get(blk, 0) + 1\n",
    "        block_trainable[blk] = block_trainable.get(blk, False) or layer.trainable\n",
    "    rows = []\n",
    "    for blk in sorted(block_layers):\n",
    "        name = f\"block{blk}\" if blk > 0 else \"stem/head\"\n",
    "        rows.append(\n",
    "            (name, str(block_layers[blk]), \"Yes\" if block_trainable[blk] else \"No\")\n",
    "        )\n",
    "    headers = (\"Block\", \"Layers\", \"Trainable\")\n",
    "    col1 = max(len(r[0]) for r in rows + [headers])\n",
    "    col2 = max(len(r[1]) for r in rows + [headers])\n",
    "    col3 = max(len(r[2]) for r in rows + [headers])\n",
    "    total_w = col1 + col2 + col3 + 6\n",
    "    border = \"=\" * total_w\n",
    "    print(f\"\\n{border}\")\n",
    "    print(\n",
    "        f\"{headers[0].ljust(col1)} | {headers[1].rjust(col2)} | {headers[2].rjust(col3)}\"\n",
    "    )\n",
    "    print(border)\n",
    "    for name, cnt, tf in rows:\n",
    "        print(f\"{name.ljust(col1)} | {cnt.rjust(col2)} | {tf.rjust(col3)}\")\n",
    "    print(border + \"\\n\")\n",
    "\n",
    "\n",
    "def prepare_dataset(cfg: ExperimentConfig):\n",
    "    dc = cfg.data\n",
    "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        dc.data_dir,\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"binary\",\n",
    "        batch_size=dc.batch_size,\n",
    "        image_size=(dc.img_size, dc.img_size),\n",
    "        validation_split=dc.validation_split,\n",
    "        subset=\"training\",\n",
    "        seed=dc.seed,\n",
    "    )\n",
    "    val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        dc.data_dir,\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"binary\",\n",
    "        batch_size=dc.batch_size,\n",
    "        image_size=(dc.img_size, dc.img_size),\n",
    "        validation_split=dc.validation_split,\n",
    "        subset=\"validation\",\n",
    "        seed=dc.seed,\n",
    "    )\n",
    "    return train_ds.prefetch(tf.data.AUTOTUNE), val_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "def build_model(cfg: ExperimentConfig):\n",
    "    mc = cfg.model\n",
    "    img_size = cfg.data.img_size\n",
    "    base = getattr(keras.applications, mc.backbone)(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\" if mc.pretrained else None,\n",
    "        input_shape=(img_size, img_size, 3),\n",
    "    )\n",
    "    block_nums = {\n",
    "        int(m.group(1))\n",
    "        for layer in base.layers\n",
    "        if (m := re.match(r\"^block(\\d+)[a-z]?_\", layer.name))\n",
    "    }\n",
    "    unique_blocks = sorted(block_nums)\n",
    "    if mc.blocks_to_unfreeze:\n",
    "        target_blocks = mc.blocks_to_unfreeze\n",
    "    else:\n",
    "        target_blocks = unique_blocks[-mc.unfreeze_blocks :]\n",
    "    for layer in base.layers:\n",
    "        m = re.match(r\"^block(\\d+)[a-z]?_\", layer.name)\n",
    "        freeze = not (\n",
    "            m\n",
    "            and int(m.group(1)) in target_blocks\n",
    "            and not isinstance(layer, layers.BatchNormalization)\n",
    "        )\n",
    "        layer.trainable = not freeze\n",
    "    inp = keras.Input((img_size, img_size, 3))\n",
    "    x = base(inp, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(mc.dropout_rate)(x)\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inp, out)\n",
    "    return model, base\n",
    "\n",
    "\n",
    "def compile_and_train(model: keras.Model, train_ds, val_ds, cfg: ExperimentConfig):\n",
    "    tc = cfg.training\n",
    "    cb = cfg.callbacks\n",
    "    opt = getattr(keras.optimizers, tc.optimizer)(learning_rate=tc.learning_rate)\n",
    "    model.compile(optimizer=opt, loss=tc.loss, metrics=tc.metrics)\n",
    "    callbacks = []\n",
    "    if cb.tensorboard_logdir:\n",
    "        callbacks.append(keras.callbacks.TensorBoard(log_dir=cb.tensorboard_logdir))\n",
    "    if cb.checkpoint_dir:\n",
    "        p = Path(cb.checkpoint_dir)\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "        callbacks.append(\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath=str(p / \"ckpt_{epoch}.keras\"),\n",
    "                save_best_only=True,\n",
    "                monitor=\"val_loss\",\n",
    "            )\n",
    "        )\n",
    "    return model.fit(\n",
    "        train_ds, validation_data=val_ds, epochs=tc.epochs, callbacks=callbacks\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    hist = history.history\n",
    "    epochs = range(1, len(hist[\"loss\"]) + 1)\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, hist[\"loss\"], label=\"Training Loss\")\n",
    "    plt.plot(epochs, hist[\"val_loss\"], label=\"Validation Loss\")\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    if \"accuracy\" in hist:\n",
    "        plt.figure()\n",
    "        plt.plot(epochs, hist[\"accuracy\"], label=\"Training Accuracy\")\n",
    "        plt.plot(epochs, hist[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "        plt.title(\"Accuracy\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def report_results(model: keras.Model, val_ds):\n",
    "    try:\n",
    "        y_true, y_pred = [], []\n",
    "        for x_batch, y_batch in val_ds.unbatch().batch(1024):\n",
    "            preds = (model.predict(x_batch) > 0.5).astype(int).flatten()\n",
    "            y_true.extend(y_batch.numpy().astype(int))\n",
    "            y_pred.extend(preds.tolist())\n",
    "        print(\"\\nClassification Report:\\n\")\n",
    "        print(classification_report(y_true, y_pred, digits=4))\n",
    "    except Exception as e:\n",
    "        print(f\"\\nCould not compute classification report: {e}\")\n",
    "\n",
    "\n",
    "def run_experiment(experiment_name: str = \"experiment\", **overrides):\n",
    "    cfg = ExperimentConfig()\n",
    "    for section, params in overrides.items():\n",
    "        if hasattr(cfg, section) and isinstance(params, dict):\n",
    "            old = getattr(cfg, section)\n",
    "            new = replace(old, **params)\n",
    "            cfg = replace(cfg, **{section: new})\n",
    "        else:\n",
    "            raise ValueError(f'Unknown section \"{section}\" or invalid params')\n",
    "    cfg_dict = {}\n",
    "    flat = asdict(cfg)\n",
    "    for sec, sec_vals in flat.items():\n",
    "        for k, v in sec_vals.items():\n",
    "            cfg_dict[f\"{sec}.{k}\"] = v\n",
    "    print_block(\"Experiment Config\", cfg_dict)\n",
    "    train_ds, val_ds = prepare_dataset(cfg)\n",
    "    model, base = build_model(cfg)\n",
    "    summarize_model(base)\n",
    "    history = compile_and_train(model, train_ds, val_ds, cfg)\n",
    "    plot_history(history)\n",
    "    report_results(model, val_ds)\n",
    "    if cfg.callbacks.save_model:\n",
    "        save_path = Path(cfg.callbacks.model_save_dir)\n",
    "        save_path.mkdir(parents=True, exist_ok=True)\n",
    "        model.save(save_path / f\"{experiment_name}.keras\")\n",
    "    return {\"history\": history, \"model\": model}\n",
    "\n",
    "\n",
    "PREFIX_MAP = [\n",
    "    (\"baseline\", \"Baseline\"),\n",
    "    (\"block\", \"Blocks\"),\n",
    "    (\"lr\", \"Learning Rate\"),\n",
    "    (\"optimizer\", \"Optimizers\"),\n",
    "    (\"dropout\", \"Dropouts\"),\n",
    "    (\"batchsize\", \"Batch Sizes\"),\n",
    "]\n",
    "\n",
    "\n",
    "def categorize(key):\n",
    "    for pfx, label in PREFIX_MAP:\n",
    "        if key.startswith(pfx):\n",
    "            return label\n",
    "    return \"Other\"\n",
    "\n",
    "\n",
    "def report_experiments(exp: dict, alpha: float = 0.25):\n",
    "    rows = []\n",
    "    for name, res in exp.items():\n",
    "        hist = res[\"history\"].history\n",
    "        val_loss = hist[\"val_loss\"]\n",
    "        train_loss = hist[\"loss\"]\n",
    "        val_acc = hist.get(\"val_accuracy\")\n",
    "        best_idx = int(pd.Series(val_loss).idxmin())\n",
    "        rows.append(\n",
    "            {\n",
    "                \"Experiment\": name,\n",
    "                \"Category\": categorize(name),\n",
    "                \"Validation Accuracy\": val_acc[best_idx],\n",
    "                \"Validation Loss\": val_loss[best_idx],\n",
    "                \"Overfit Gap\": val_loss[best_idx] - train_loss[best_idx],\n",
    "            }\n",
    "        )\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"NormLoss\"] = df.groupby(\"Category\")[\"Validation Loss\"].transform(\n",
    "        lambda s: (s - s.min()) / (s.max() - s.min()) if s.max() != s.min() else 0.0\n",
    "    )\n",
    "    df[\"NormGap\"] = df.groupby(\"Category\")[\"Overfit Gap\"].transform(\n",
    "        lambda s: (s - s.min()) / (s.max() - s.min()) if s.max() != s.min() else 0.0\n",
    "    )\n",
    "    df[\"Score\"] = alpha * (1 - df[\"NormLoss\"]) + (1 - alpha) * (1 - df[\"NormGap\"])\n",
    "    display(df.drop(columns=[\"NormGap\"]).round(4))\n",
    "    best = df.loc[df[\"Score\"].idxmax()]\n",
    "    best_by_cat = (\n",
    "        df.sort_values(\"Score\", ascending=False)\n",
    "        .groupby(\"Category\", as_index=False)\n",
    "        .first()[\n",
    "            [\n",
    "                \"Category\",\n",
    "                \"Experiment\",\n",
    "                \"Validation Accuracy\",\n",
    "                \"Validation Loss\",\n",
    "                \"Overfit Gap\",\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "    display(best_by_cat.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ShJs0oObC1NE"
   },
   "outputs": [],
   "source": [
    "exp = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "This will be used for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp['baseline'] = run_experiment(experiment_name='baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-aIAiU5qsCG"
   },
   "source": [
    "## Blocks\n",
    "-  Earlier layers tend to learn very general features\n",
    "-  Later blocks capture more specialized patterns\n",
    "\n",
    "Fine-tune varying depths by testing it empirically to identify which one will work the best for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vny5QklXqsCG",
    "outputId": "ac8ba257-fe7a-42bc-af76-922d443d51b0"
   },
   "outputs": [],
   "source": [
    "for b in [7, 6, 5, 4, 3, 2, 1]:\n",
    "    exp[f'block_{b}'] = run_experiment(\n",
    "        experiment_name=f'block_{b}',\n",
    "        model={'unfreeze_blocks': b},\n",
    "        callbacks={\"save_model\": True},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GouWBHonqsCH"
   },
   "source": [
    "## Learning Rates\n",
    "Balance fast convergence against stability\n",
    "- Too high a rate can skip over minima\n",
    "- Too low may cause painfully slow training or getting stuck in poor local minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTQihYoRqsCH",
    "outputId": "5dba4bf5-0ad8-4038-e2ef-63a9eb2fb2cd"
   },
   "outputs": [],
   "source": [
    "for lr in [1e-3, 1e-4, 1e-5]:\n",
    "    exp[f'lr_{lr}'] = run_experiment(\n",
    "        experiment_name=f'lr_{lr}',\n",
    "        training={'learning_rate': lr},\n",
    "        callbacks={\"save_model\": True},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6Yb0VqHqsCI"
   },
   "source": [
    "## Optimizer Variations\n",
    "Different optimizers to assess optimization dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ROtulB9kqsCI",
    "outputId": "7136a132-d6d3-4528-9044-95cf433d4f32"
   },
   "outputs": [],
   "source": [
    "for opt in ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam']:\n",
    "    exp[f'optimizer_{opt}'] = run_experiment(\n",
    "        experiment_name=f'optimizer_{opt}',\n",
    "        training={'optimizer': opt},\n",
    "        callbacks={\"save_model\": True},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iviqaovtqsCI"
   },
   "source": [
    "## Dropouts\n",
    "To find the balance between robustness and capacity\n",
    "- Lower rates: make training more stable but might under-regularize\n",
    "- higher rates: inject more noise to prevent co-adaptation of filters and combat overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SEFVBso9qsCJ",
    "outputId": "92479a85-ed85-4946-f0ea-a223c56c9801"
   },
   "outputs": [],
   "source": [
    "for dr in [0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    exp[f'dropout_{dr}'] = run_experiment(\n",
    "        experiment_name=f'dropout_{dr}',\n",
    "        model={'dropout_rate': dr},\n",
    "        callbacks={\"save_model\": True},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPiKIIL4qsCJ"
   },
   "source": [
    "## Batch Size\n",
    "Trade-off between gradient‐estimate noise and computational efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aOJnx3JMqsCJ",
    "outputId": "adfbd4e3-dcd6-44a3-f634-44af63104007"
   },
   "outputs": [],
   "source": [
    "for bs in [32, 16, 8, 4, 2, 1]:\n",
    "    exp[f\"batchsize_{bs}\"] = run_experiment(\n",
    "        experiment_name=f\"batchsize_{bs}\",\n",
    "        data={\"batch_size\": bs},\n",
    "        callbacks={\"save_model\": True},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0L1RONWoqsCK",
    "outputId": "66a4c709-5f74-4922-82cc-32e05e6662d5"
   },
   "outputs": [],
   "source": [
    "report_experiments(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJmUOJ7RqsCK"
   },
   "source": [
    "## Best Model\n",
    "Test to see if the best in each set of experiments will produce a better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UgLgNqyEqsCK",
    "outputId": "12b22d8d-145b-4c36-bbdb-7a97dfa09e86"
   },
   "outputs": [],
   "source": [
    "exp['best'] = run_experiment(\n",
    "    data={\n",
    "        'batch_size': 16\n",
    "    },\n",
    "    model={\n",
    "        'unfreeze_blocks': 6,\n",
    "        'dropout_rate': 0.6\n",
    "    },\n",
    "    training={\n",
    "        'epochs': 30,\n",
    "        'learning_rate': 1e-3,\n",
    "        'optimizer': 'Adam'\n",
    "    },\n",
    "    callbacks={\n",
    "        'save_model': True\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_experiments(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
